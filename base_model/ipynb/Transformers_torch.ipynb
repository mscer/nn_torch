{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2547e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0d925",
   "metadata": {},
   "source": [
    "# data/model/loss/optimize/init/train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08f4cc",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6c6153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b813b5f",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e69b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensordot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9193bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Softmax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d007db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self,num_head=4,dim_hidden=256,):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        ##query,key,value\n",
    "        self.num_head = num_head\n",
    "        self.dim_head = dim_hidden/4\n",
    "        self.proj_q = torch.nn.Linear(in_features=dim_hidden,out_features=num_head*self.dim_head)\n",
    "        self.proj_k = torch.nn.Linear(in_features=dim_hidden,out_features=num_head*self.dim_head)\n",
    "        self.proj_v = torch.nn.Linear(in_features=dim_hidden,out_features=num_head*self.dim_head)\n",
    "        \n",
    "        self.sfm = torch.nn.Softmax()\n",
    "    \n",
    "    def forward(self,query,key,value,mask):\n",
    "        ##[batch_size,seq_len,dim]\n",
    "        query = self.proj_q(query)\n",
    "        key = self.proj_q(query)\n",
    "        value=selff.proj_q(query)\n",
    "        \n",
    "        ##[batch_size,num_head,seq_len,dim_head]\n",
    "        query = self.split_head(query)\n",
    "        key = self.split_head(key)\n",
    "        value = self.split_head(value)\n",
    "        \n",
    "        ##attention\n",
    "        ##[[batch_size,num_head,seq_len,dim_head]]->[batch_size,num_head,seq_len,seq_len]\n",
    "        att_weight = torch.tensordot(query,key,dims=([-1],[-1]))\n",
    "        scaled_ratio = torch.sqrt(query.shape[-1])\n",
    "        att_weight/=scaled_ratio\n",
    "        ##mask: batch_size,seq_len,seqq_len\n",
    "        ##causal mask for decoder and padding_mask for encoder and decoder\n",
    "        if mask is not None:\n",
    "            att_weight += (1-mask)*-1*e**9\n",
    "        att_weight = self.sfm(att_weight)\n",
    "        \n",
    "        ##[batch_size,num_head,seq_len,seq_len] *[batch_size,num_head,seq_len,dim_head]\n",
    "        output = torch.tensordot(att_weight,value,dims=([-1],[-1]))\n",
    "        output = torch.permute(output,[0,2,1,3]).view(output.shape[0],output.shape[1],-1)\n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def split_head(self,x):\n",
    "        ##[batch_size,seq_len,dim]->##[batch_size,seq_len,num_head,dim_head]\n",
    "        x = x.view(x.shape[0] ,x.shape[1],self.num_head,-1)\n",
    "        #[batch_size,seq_len,num_head,dim_head]->#[batch_size,num_head,seq_len,dim_head]\n",
    "        x = torch.permute(x,[0,2,1,3])\n",
    "        return x",
    "    def post_init(self):n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                # print('before',m.weight,)\n",
    "                torch.nn.init.xavier_normal(m.weight)\n",
    "                #print('after',m.weight)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17148d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(60.).reshape(3, 4, 5)\n",
    "b = torch.arange(60.).reshape(3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1581f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 3, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensordot(a,b,dims=([-1],[-1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfe13490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,10).repeat(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25673c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.MultiheadAttention??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56fcdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.multi_head_attention_forward??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6c0097c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48ac328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.MultiHeadAttention??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0df8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.repeat_interleave?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d848df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.sequence_mask??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da1d5a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange((10)) < torch.arange(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb308da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
