{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7dcec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6566531c",
   "metadata": {},
   "source": [
    "# data/model/loss/optimize/init/train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae227c3",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf30cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1bb94a4",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39eb5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "##encoder 2 decoer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eefbb0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6eae620",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.GRU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14368589",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.permute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e5b5428",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.squeeze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af8966a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self,num_token,dim_embed,num_hidden,dim_hidden):\n",
    "        super(Encoder,self).__init__()\n",
    "        ##embed\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=num_token,embedding_dim=dim_embed)\n",
    "        self.gru = torch.nn.GRU(input_size = dim_embed,hidden_size=dim_hidden,num_layers=num_hidden\n",
    "                                ,bias = True,bidirectional = True)\n",
    "    def forward(self, x):\n",
    "        ##non batch first\n",
    "        ##batch_size,seq_len,dim -> seq_len,batch_size,dim\n",
    "        x = self.embedding(x)\n",
    "        x = torch.permute(x,[1,0,2])\n",
    "        output,h_n = self.gru(x)\n",
    "        #h_n:seq_len,batch_size,num_directions,dim\n",
    "        print(output.shape)\n",
    "        print(h_n.shape)\n",
    "        #h_n = h_n[-1*2]\n",
    "        return output,h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a845610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 4, 32])\n",
      "torch.Size([4, 4, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 4, 32]), torch.Size([4, 4, 16]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(num_token =10, dim_embed=8, dim_hidden=16,\n",
    "                         num_hidden=2)\n",
    "encoder.eval()\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "output, state = encoder(X)\n",
    "output.shape,state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self,num_token,dim_embed,num_hidden,dim_hidden):\n",
    "        super(Encoder,self).__init__()\n",
    "        ##embed\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=num_token,embedding_dim=dim_embed)\n",
    "        self.gru = torch.nn.GRU(input_size = dim_embed,hidden_size=dim_hidden,bias = True,bidirectional = False)\n",
    "        self.dense = torch.nn.Linear(input_size=num_hidden,out_features=num_token)\n",
    "    \n",
    "    def init_state(self,encoding_out):\n",
    "        return encoding_out[-1]\n",
    "    \n",
    "    def forward(self,x,state):\n",
    "        ##x:batch_size,seq_len,dim\n",
    "        ##state:batch_size,num_layers,dim\n",
    "        x = torch.permute(x,[1,0,2])\n",
    "        state = torch.permute(state,[1,0,2])\n",
    "        state = self.init(state)\n",
    "        output,state = self.gru(x,state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
